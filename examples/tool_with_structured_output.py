#!/usr/bin/env python3
"""
å·¥å…·è°ƒç”¨ä¸ç»“æ„åŒ–è¾“å‡ºé›†æˆç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•æ­£ç¡®åœ°ç»“åˆå·¥å…·è°ƒç”¨å’Œç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ã€‚
åŸºäºå¯¹ vLLM è¡Œä¸ºçš„æ·±å…¥æµ‹è¯•ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆ†é˜¶æ®µå¤„ç†çš„æ–¹æ³•ã€‚
"""

from langchain_core.tools import tool
from langchain_core.messages import ToolMessage, HumanMessage, SystemMessage
from pydantic import BaseModel, Field
from langchain_qwq.chat_models_vllm import ChatQwenVllm


# å®šä¹‰å·¥å…·
@tool
def get_weather(location: str, unit: str = "celsius") -> str:
    """è·å–æŒ‡å®šåœ°ç‚¹çš„å½“å‰å¤©æ°”ä¿¡æ¯.
    
    Args:
        location: è¦æŸ¥è¯¢å¤©æ°”çš„åŸå¸‚æˆ–åœ°ç‚¹
        unit: æ¸©åº¦å•ä½ï¼Œ'celsius' æˆ– 'fahrenheit'
    
    Returns:
        æè¿°å½“å‰å¤©æ°”çŠ¶å†µçš„å­—ç¬¦ä¸²
    """
    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    weather_data = {
        "beijing": {"temp": 22, "condition": "sunny", "humidity": 60},
        "shanghai": {"temp": 25, "condition": "cloudy", "humidity": 75},
        "tokyo": {"temp": 20, "condition": "sunny", "humidity": 55},
        "london": {"temp": 15, "condition": "rainy", "humidity": 80}
    }
    
    location_lower = location.lower()
    if location_lower in weather_data:
        data = weather_data[location_lower]
        temp_unit = "Â°C" if unit == "celsius" else "Â°F"
        if unit == "fahrenheit":
            data["temp"] = int(data["temp"] * 9/5 + 32)
        
        return f"å½“å‰{location}çš„å¤©æ°”ï¼š{data['condition']}ï¼Œ{data['temp']}{temp_unit}ï¼Œæ¹¿åº¦{data['humidity']}%"
    else:
        return f"æš‚æ— {location}çš„å¤©æ°”æ•°æ®"


# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
class WeatherQuery(BaseModel):
    """å¤©æ°”æŸ¥è¯¢ç»“æœæ¶æ„."""
    location: str = Field(description="æŸ¥è¯¢çš„åœ°ç‚¹")
    temperature: int = Field(description="æ¸©åº¦æ•°å€¼ï¼ˆä¸å«å•ä½ï¼‰")
    condition: str = Field(description="å¤©æ°”çŠ¶å†µ")
    humidity: int = Field(description="æ¹¿åº¦ç™¾åˆ†æ¯”", ge=0, le=100)
    unit: str = Field(description="æ¸©åº¦å•ä½", pattern="^(celsius|fahrenheit)$")


def basic_example():
    """åŸºæœ¬ç¤ºä¾‹ï¼šå·¥å…·è°ƒç”¨ + ç»“æ„åŒ–è¾“å‡º"""
    print("ğŸŒŸ åŸºæœ¬ç¤ºä¾‹ï¼šå·¥å…·è°ƒç”¨ + ç»“æ„åŒ–è¾“å‡º")
    print("=" * 50)
    
    # åˆå§‹åŒ– LLM
    llm = ChatQwenVllm(
        model="Qwen/Qwen3-32B",
        api_base="http://localhost:8000/v1",
        temperature=0.1,
    )
    
    # é˜¶æ®µ1: å·¥å…·è°ƒç”¨ï¼ˆä¸ä½¿ç”¨ guided_jsonï¼‰
    print("ğŸ“ é˜¶æ®µ1: å·¥å…·è°ƒç”¨...")
    llm_with_tools = llm.bind_tools([get_weather])
    
    initial_messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”åŠ©æ‰‹ã€‚ä½¿ç”¨å¯ç”¨çš„å·¥å…·è·å–å‡†ç¡®çš„å¤©æ°”ä¿¡æ¯ã€‚"),
        HumanMessage(content="ä¸œäº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
    ]
    
    tool_response = llm_with_tools.invoke(initial_messages)
    print(f"   å·¥å…·è°ƒç”¨å“åº”ç±»å‹: {type(tool_response)}")
    
    if hasattr(tool_response, 'tool_calls') and tool_response.tool_calls:
        print(f"   ç”Ÿæˆäº† {len(tool_response.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        tool_messages = []
        for tool_call in tool_response.tool_calls:
            if tool_call['name'] == 'get_weather':
                print(f"   æ‰§è¡Œå·¥å…·: {tool_call['name']} with {tool_call['args']}")
                tool_result = get_weather.invoke(tool_call['args'])
                print(f"   å·¥å…·ç»“æœ: {tool_result}")
                
                tool_messages.append(
                    ToolMessage(
                        content=tool_result,
                        tool_call_id=tool_call['id']
                    )
                )
    else:
        print("   âš ï¸ æ²¡æœ‰ç”Ÿæˆå·¥å…·è°ƒç”¨")
        return
    
    # é˜¶æ®µ2: ç»“æ„åŒ–è¾“å‡ºï¼ˆä½¿ç”¨ guided_jsonï¼‰
    print("\nğŸ“Š é˜¶æ®µ2: ç»“æ„åŒ–è¾“å‡º...")
    structured_llm = llm.with_structured_output(
        schema=WeatherQuery,
        method="json_schema"
    )
    
    # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„å®Œæ•´å¯¹è¯
    conversation_with_tools = initial_messages + [tool_response] + tool_messages
    
    # æ·»åŠ ç»“æ„åŒ–è¾“å‡ºæŒ‡ä»¤
    final_messages = conversation_with_tools + [
        HumanMessage(content="""æ ¹æ®å·¥å…·æä¾›çš„å¤©æ°”ä¿¡æ¯ï¼Œè¯·æŒ‰ç…§ WeatherQuery æ¶æ„æ ¼å¼åŒ–å“åº”ï¼š
1. æå–æ•°å€¼æ¸©åº¦ï¼ˆä¸å«å•ä½ç¬¦å·ï¼‰
2. unit å­—æ®µå¿…é¡»æ˜¯ 'celsius' æˆ– 'fahrenheit'
3. ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å·²æ­£ç¡®å¡«å†™""")
    ]
    
    structured_response = structured_llm.invoke(final_messages)
    print(f"   ç»“æ„åŒ–å“åº”ç±»å‹: {type(structured_response)}")
    
    if isinstance(structured_response, WeatherQuery):
        print("   âœ… æˆåŠŸè·å¾—ç»“æ„åŒ–æ•°æ®:")
        print(f"      ä½ç½®: {structured_response.location}")
        print(f"      æ¸©åº¦: {structured_response.temperature}")
        print(f"      çŠ¶å†µ: {structured_response.condition}")
        print(f"      æ¹¿åº¦: {structured_response.humidity}%")
        print(f"      å•ä½: {structured_response.unit}")
    else:
        print(f"   âŒ æœªè·å¾—é¢„æœŸçš„ç»“æ„åŒ–æ•°æ®: {structured_response}")


def include_raw_example():
    """é«˜çº§ç¤ºä¾‹ï¼šå¸¦åŸå§‹å“åº”çš„ç»“æ„åŒ–è¾“å‡º"""
    print("\nğŸ” é«˜çº§ç¤ºä¾‹ï¼šinclude_raw=True")
    print("=" * 50)
    
    llm = ChatQwenVllm(
        model="Qwen/Qwen3-32B", 
        api_base="http://localhost:8000/v1",
        temperature=0.1,
    )
    
    # é˜¶æ®µ1: å·¥å…·è°ƒç”¨
    llm_with_tools = llm.bind_tools([get_weather])
    
    messages = [
        SystemMessage(content="ä½ æ˜¯å¤©æ°”åˆ†æå¸ˆã€‚ä½¿ç”¨å·¥å…·è·å–å¤šä¸ªåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚"),
        HumanMessage(content="è¯·æŸ¥è¯¢åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”ã€‚")
    ]
    
    tool_response = llm_with_tools.invoke(messages)
    
    # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
    tool_messages = []
    if hasattr(tool_response, 'tool_calls') and tool_response.tool_calls:
        for tool_call in tool_response.tool_calls:
            if tool_call['name'] == 'get_weather':
                result = get_weather.invoke(tool_call['args'])
                tool_messages.append(
                    ToolMessage(content=result, tool_call_id=tool_call['id'])
                )
    
    # é˜¶æ®µ2: å¸¦åŸå§‹å“åº”çš„ç»“æ„åŒ–è¾“å‡º
    class WeatherSummary(BaseModel):
        cities: list[str] = Field(description="æŸ¥è¯¢çš„åŸå¸‚åˆ—è¡¨")
        overall_condition: str = Field(description="æ€»ä½“å¤©æ°”çŠ¶å†µ")
        temperature_range: str = Field(description="æ¸©åº¦èŒƒå›´æè¿°")
    
    structured_llm = llm.with_structured_output(
        schema=WeatherSummary,
        method="json_schema",
        include_raw=True
    )
    
    conversation = messages + [tool_response] + tool_messages
    final_messages = conversation + [
        HumanMessage(content="æ ¹æ®å·¥å…·è·å–çš„å¤©æ°”ä¿¡æ¯ï¼Œæä¾›ä¸€ä¸ªç»¼åˆçš„å¤©æ°”æ‘˜è¦ã€‚")
    ]
    
    response = structured_llm.invoke(final_messages)
    
    if isinstance(response, dict) and "raw" in response:
        print("   âœ… è·å¾—å¸¦åŸå§‹å“åº”çš„ç»“æ„åŒ–æ•°æ®:")
        print(f"   åŸå§‹å“åº”ç±»å‹: {type(response['raw'])}")
        print(f"   è§£æçŠ¶æ€: {'æˆåŠŸ' if response['parsing_error'] is None else 'å¤±è´¥'}")
        
        if response['parsed']:
            parsed = response['parsed']
            print(f"   åŸå¸‚: {parsed.cities}")
            print(f"   æ€»ä½“çŠ¶å†µ: {parsed.overall_condition}")
            print(f"   æ¸©åº¦èŒƒå›´: {parsed.temperature_range}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ vLLM å·¥å…·è°ƒç”¨ä¸ç»“æ„åŒ–è¾“å‡ºé›†æˆç¤ºä¾‹")
    print("åŸºäºåˆ†é˜¶æ®µå¤„ç†çš„æ­£ç¡®å®ç°æ–¹å¼")
    print("=" * 60)
    
    try:
        basic_example()
        include_raw_example()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ç¤ºä¾‹å®Œæˆï¼")
        print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
        print("1. å·¥å…·è°ƒç”¨é˜¶æ®µï¼šåªå‘é€ toolsï¼Œä¸å‘é€ guided_json")
        print("2. ç»“æ„åŒ–è¾“å‡ºé˜¶æ®µï¼šåªå‘é€ guided_jsonï¼Œä¸å‘é€ tools")
        print("3. é€šè¿‡å¯¹è¯å†å²ä¼ é€’å·¥å…·è°ƒç”¨ç»“æœ")
        print("4. ä¸¤ä¸ªé˜¶æ®µåˆ†åˆ«ä¼˜åŒ–ï¼Œç¡®ä¿æœ€ä½³æ•ˆæœ")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿ vLLM æœåŠ¡å™¨æ­£åœ¨è¿è¡Œå¹¶åŠ è½½äº†ç›¸åº”æ¨¡å‹")


if __name__ == "__main__":
    main()
